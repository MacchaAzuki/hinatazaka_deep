{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "from IPython.display import clear_output, display, Image\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append('../')\n",
    "from model import Model\n",
    "\n",
    "sys.path.append(\"../face_detection/\")\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils_color as vis_util\n",
    "from tensorflow_face_detector import TensoflowFaceDector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    0: \"iguchi\",\n",
    "    1: \"ushio\",\n",
    "    2: \"kakizaki\",\n",
    "    3: \"kageyama\",\n",
    "    4: \"kato\",\n",
    "    5: \"saito\",\n",
    "    6: \"sasaki_k\",\n",
    "    7: \"sasaki_m\",\n",
    "    8: \"takase\" ,\n",
    "    9: \"takamoto\" ,\n",
    "    10: \"higashimura\",\n",
    "    11: \"kanemura\",\n",
    "    12: \"kawata\",\n",
    "    13: \"kosaka\",\n",
    "    14: \"tomita\",\n",
    "    15: \"nibu\",\n",
    "    16: \"hamagishi\",\n",
    "    17: \"matsuda\",\n",
    "    18: \"miyata\",\n",
    "    19: \"watanabe\",\n",
    "    20: \"kamimura\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_n_faces(imageFile):\n",
    "    image = cv2.imread(imageFile)\n",
    "    faceDetectImage = image.copy()\n",
    "    [h, w] = faceDetectImage.shape[:2]\n",
    "\n",
    "    (boxes, scores, classes, num_detections) = tDetector.run(faceDetectImage)\n",
    "\n",
    "    faceBoxes = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        faceDetectImage,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=4)\n",
    "    \n",
    "    personCount = len(faceBoxes)\n",
    "        \n",
    "    imageHeight, imageWidth = image.shape[:2]\n",
    "    \n",
    "    originBoxes = []\n",
    "    cropBoxes = []\n",
    "    \n",
    "    for index, box in enumerate(faceBoxes):\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        (left, right, top, bottom) = (int(xmin * imageWidth), int(xmax * imageWidth), int(ymin * imageHeight), int(ymax * imageHeight))\n",
    "        originBoxes.append((left, right, top, bottom))  # TensorFlowの顔検出で切り取った領域\n",
    "        \n",
    "        cropWidth = right - left\n",
    "        cropHeight = bottom - top\n",
    "        \n",
    "        # 長辺に合わせる\n",
    "        if cropHeight > cropWidth:\n",
    "            diff  = (cropHeight - cropWidth) / 2\n",
    "            if int(left - diff) < 0 or int(right + diff) > imageWidth:\n",
    "                top = int(top + diff)\n",
    "                bottom = int(bottom - diff)\n",
    "            else:\n",
    "                left = int(left - diff)\n",
    "                right = int(right + diff)\n",
    "        else:\n",
    "            diff = (cropWidth - cropHeight) / 2\n",
    "            if int(top - diff) < 0 or int(bottom + diff) > imageHeight:\n",
    "                left = int(left + diff)\n",
    "                right = int(right - diff)\n",
    "            else:\n",
    "                top = int(top - diff)\n",
    "                bottom = int(bottom + diff)\n",
    "        \n",
    "        cropBoxes.append((left, right, top, bottom))   # 顔検出に用いる正方形領域\n",
    "        \n",
    "    return originBoxes, cropBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ解析\n",
    "def read_image(images):     \n",
    "    image = tf.cast(images, tf.float32)\n",
    "    image = image / 255  # 画像データを、0～1の範囲に変換する\n",
    "    image = tf.reshape(image, [128, 128, 3])\n",
    "     \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = '../face_detection/model/frozen_inference_graph_face.pb'\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = '../face_detection/protos/face_label_map.pbtxt'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "tDetector = TensoflowFaceDector(PATH_TO_CKPT)# モデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力フォルダ作成\n",
    "originImagePath = '../images/origin/'\n",
    "originImageMemberPath = glob.glob(originImagePath + \"*\")\n",
    "for index, memberPath in enumerate(originImageMemberPath):\n",
    "    memberPath = memberPath.replace(\"\\\\\", '/') + '/'\n",
    "    originImageMemberPath[index] = memberPath        \n",
    "    outputOriginImageMemberPath = 'output_images/' + 'origin/' + memberPath.split('/')[-2] + '/'\n",
    "    os.makedirs(outputOriginImageMemberPath + '1/', exist_ok=True)\n",
    "    os.makedirs(outputOriginImageMemberPath + '2/', exist_ok=True)\n",
    "    os.makedirs(outputOriginImageMemberPath + '3_over/', exist_ok=True)\n",
    "\n",
    "os.makedirs('output_images/origin/others/1/', exist_ok=True)\n",
    "os.makedirs('output_images/origin/others/2/', exist_ok=True)\n",
    "os.makedirs('output_images/origin/others/3_over/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceIdentificationAndCopyFiles(imageFiles, maxFaces, ckptPath):\n",
    "    \n",
    "    fileNames = [] # ファイル名のリスト\n",
    "    detectFacesNum = [] # ファイルごとの検出した顔の数\n",
    "    cropImages = [] # 切り取った顔のリスト\n",
    "    \n",
    "    for imageFile in imageFiles:\n",
    "        sourceImage = cv2.imread(imageFile)\n",
    "        originBoxes, cropBoxes = detect_n_faces(imageFile)\n",
    "\n",
    "        # 指定人数より多い or 1つも顔が検出されなければ次へ\n",
    "        if len(cropBoxes) > maxFaces or len(cropBoxes) == 0:\n",
    "            continue\n",
    "\n",
    "        fileNames.append(imageFile)\n",
    "        \n",
    "        # 検出された顔の数をカウント\n",
    "        nDetectFace = 0\n",
    "        for box in cropBoxes:\n",
    "            (left, right, top, bottom) = box\n",
    "            cropImages.append(sourceImage[top:bottom, left:right])\n",
    "            nDetectFace += 1\n",
    "            \n",
    "        detectFacesNum.append(nDetectFace)\n",
    "\n",
    "    # テンソル用の準備\n",
    "    imgs = np.empty((0, 128, 128, 3)) #empty dummy array, we will append to this array all the images\n",
    "    for img in cropImages:\n",
    "        img = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_LANCZOS4)\n",
    "        img = img[:, :, ::-1].copy()\n",
    "        imgs = np.append(imgs, np.array(img).reshape((1, 128, 128, 3)), axis=0)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(imgs)\n",
    "        dataset = dataset.map(read_image, len(cropImages))  # データの形式、形状を変更\n",
    "        dataset = dataset.batch(len(cropImages))  # 連続するレコードをバッチに結合\n",
    "        iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)  # イテレータを作成\n",
    "        images = iterator.get_next()  # イテレータの次の要素を取得\n",
    "\n",
    "        initOp = iterator.make_initializer(dataset)  # イテレータを初期化\n",
    "\n",
    "        model = Model(images, 128, 21, len(cropImages), trainable=False)\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            session.run(initOp)  # データの初期化\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(session, ckptPath)\n",
    "\n",
    "            estimationResult, resultImages = session.run([model.logits, images], feed_dict={model.keepProb: 1.0, model.isTraining: False})\n",
    "            \n",
    "    for index, fileName in enumerate(fileNames):\n",
    "        # 2人以下ならそのままフォルダ名に\n",
    "        if detectFacesNum[index] < 3:\n",
    "            saveFolderDetectFaces = str(detectFacesNum[index]) + '/'\n",
    "        else:\n",
    "            saveFolderDetectFaces = '3_over/'\n",
    "        \n",
    "        # 検出した顔を識別してフォルダにコピー\n",
    "        for faceIndex in range(detectFacesNum[index]):\n",
    "            estimation = estimationResult[index + faceIndex]               \n",
    "            \n",
    "            if np.max(estimation) < 0.5:\n",
    "                saveFolder = 'output_images/' + 'origin/' + 'others/' + saveFolderDetectFaces\n",
    "            else:\n",
    "                idFaceMemberName = names[np.argmax(estimation)]\n",
    "                saveFolder = 'output_images/'+ 'origin/' + idFaceMemberName + '/' + saveFolderDetectFaces\n",
    "            shutil.copy(fileName, saveFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPickImages = 50\n",
    "ckptPath = 'recognition_model/model.ckpt-101881'\n",
    "for memberImageFolder in originImageMemberPath:\n",
    "    imageFiles = glob.glob(memberImageFolder + '*')\n",
    "    nFiles = len(imageFiles)\n",
    "    \n",
    "    for i in range(math.ceil(nFiles / nPickImages)):\n",
    "        startIndex = i * nPickImages\n",
    "        if (i + 1) * nPickImages > nFiles:\n",
    "            endIndex = nFiles\n",
    "        else:\n",
    "            endIndex = (i + 1) * nPickImages\n",
    "            \n",
    "        pickedImages = imageFiles[startIndex : endIndex]\n",
    "        \n",
    "        faceIdentificationAndCopyFiles(pickedImages, 2, ckptPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
