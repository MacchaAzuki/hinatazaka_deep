{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"iguchi\": 0,\n",
    "    \"ushio\": 1,\n",
    "    \"kakizaki\": 2,\n",
    "    \"kageyama\": 3,\n",
    "    \"kato\": 4,\n",
    "    \"saito\": 5,\n",
    "    \"sasaki_k\": 6,\n",
    "    \"sasaki_m\": 7,\n",
    "    \"takase\": 8 ,\n",
    "    \"takamoto\":9 ,\n",
    "    \"higashimura\": 10,\n",
    "    \"kanemura\": 11,\n",
    "    \"kawata\": 12,\n",
    "    \"kosaka\": 13,\n",
    "    \"tomita\": 14,\n",
    "    \"nibu\": 15,\n",
    "    \"hamagishi\": 16,\n",
    "    \"matsuda\": 17,\n",
    "    \"miyata\": 18,\n",
    "    \"watanabe\": 19,\n",
    "    \"kamimura\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = \"images/face_data/\"\n",
    "learning_member_path = glob.glob(learning_path + \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_member_path = [p for p in learning_member_path if 'other' not in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = \"images/face_data/\"\n",
    "learning_member_path = glob.glob(learning_path + \"*\")\n",
    "for index, member_path in enumerate(learning_member_path):\n",
    "    learning_member_path[index] = member_path.replace(\"\\\\\", '/')\n",
    "    \n",
    "    # それぞれのメンバーの学習用画像を全部取得\n",
    "    file_list = glob.glob(member_path + \"/\" + \"*\")\n",
    "    for image_file in file_list:\n",
    "        os.makedirs(member_path + \"/train/\", exist_ok=True)\n",
    "        shutil.move(image_file, member_path + \"/train/\" + image_file.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move test folder\n",
    "for member_path in learning_member_path:\n",
    "    file_list = glob.glob(member_path + \"/train/*\")\n",
    "    test_rate = 0.2\n",
    "    test_num = math.floor(len(file_list) * test_rate)\n",
    "    test_file_list = random.sample(file_list, test_num)\n",
    "    \n",
    "    for image_file in test_file_list:\n",
    "        os.makedirs(member_path + \"/test/\", exist_ok=True)\n",
    "        shutil.move(image_file, member_path + \"/test/\" + image_file.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "test_data_list = []\n",
    "for memberFolder in learning_member_path:\n",
    "    train_file_list = glob.glob(memberFolder + \"/train/*\")\n",
    "    test_file_list = glob.glob(memberFolder + \"/test/*\")\n",
    "    train_data_list.extend(train_file_list)\n",
    "    test_data_list.extend(test_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTensorflowReadFile(img_files, out_file):\n",
    "    with tf.python_io.TFRecordWriter(out_file) as writer:\n",
    "        for f in img_files:\n",
    "            # ファイルを開く\n",
    "            with Image.open(f) as image_object:\n",
    "                image_object = image_object.resize(size, Image.LANCZOS)\n",
    "                image = np.array(image_object)\n",
    "                image = image[:,:,::-1]# RGB -> BGR\n",
    "                 \n",
    "                height = image.shape[0]\n",
    "                width = image.shape[1]\n",
    "                image_raw = image.tostring()\n",
    "                label = names[f.split('/')[-2]] # ラベルを取得\n",
    " \n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                        \"height\": tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "                        \"width\": tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "                        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "                        \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_object.tobytes()])),\n",
    "                        \"path\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[f.encode('utf-8')]))\n",
    "                        }))\n",
    " \n",
    "            # レコード書込\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateTensorflowReadFile(train_data_list , \"train_tf_file_%sx%s.tfrecords\" % size) # 書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateTensorflowReadFile(test_data_list , \"test_tf_file_%sx%s.tfrecords\" % size) # 書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認用\n",
    "# output imagefile in tfrecord\n",
    "count = 0\n",
    "os.makedirs(\"check_tfRecords\", exist_ok=True)\n",
    "for record  in tf.python_io.tf_record_iterator(\"train_tf_file_%sx%s.tfrecords\" % size):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record)  # バイナリデータからの読み込み\n",
    " \n",
    "    height = example.features.feature[\"height\"].int64_list.value[0]\n",
    "    width = example.features.feature[\"width\"].int64_list.value[0]\n",
    "    label = example.features.feature[\"label\"].int64_list.value[0]\n",
    "    image = example.features.feature[\"image\"].bytes_list.value[0]\n",
    "    path = example.features.feature[\"path\"].bytes_list.value[0]\n",
    " \n",
    "    image = np.fromstring(image, dtype=np.uint8)\n",
    "    image = image.reshape([height, width, 3])\n",
    "    img = Image.fromarray(image, \"RGB\")\n",
    "    img.save(os.path.join(\"check_tfRecords\", \"tfrecords_{0}-{1}.jpg\".format(str(count), label)))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
