{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DST_INPUT_SIZE = 128\n",
    "NUM_CLASS = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(exampleProto):\n",
    "    features={\n",
    "            'image': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "            'label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "            'path': tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
    "        }\n",
    "    parsedFeatures = tf.parse_single_example(exampleProto, features)  # データ構造を解析\n",
    "     \n",
    "    return parsedFeatures[\"image\"], parsedFeatures[\"label\"], parsedFeatures[\"path\"]\n",
    " \n",
    "# データ解析（２）\n",
    "def read_image(images, labels, paths):     \n",
    "    image = tf.decode_raw(images, tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255  # 画像データを、0～1の範囲に変換する\n",
    "    image = tf.reshape(image, [DST_INPUT_SIZE, DST_INPUT_SIZE, 3])\n",
    "    \n",
    "    label = tf.cast(labels, tf.int32)\n",
    "    label = tf.one_hot(label, NUM_CLASS)\n",
    "    \n",
    "    pathCodePoints = tf.strings.unicode_decode(input=paths, input_encoding='UTF-8')\n",
    "    path = tf.strings.unicode_encode(pathCodePoints, output_encoding='UTF-8')\n",
    "     \n",
    "    return image, label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"iguchi\": 0,\n",
    "    \"ushio\": 1,\n",
    "    \"kakizaki\": 2,\n",
    "    \"kageyama\": 3,\n",
    "    \"kato\": 4,\n",
    "    \"saito\": 5,\n",
    "    \"sasaki_k\": 6,\n",
    "    \"sasaki_m\": 7,\n",
    "    \"takase\": 8 ,\n",
    "    \"takamoto\":9 ,\n",
    "    \"higashimura\": 10,\n",
    "    \"kanemura\": 11,\n",
    "    \"kawata\": 12,\n",
    "    \"kosaka\": 13,\n",
    "    \"tomita\": 14,\n",
    "    \"nibu\": 15,\n",
    "    \"hamagishi\": 16,\n",
    "    \"matsuda\": 17,\n",
    "    \"miyata\": 18,\n",
    "    \"watanabe\": 19,\n",
    "    \"kamimura\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckptPath= 'log/data_YYYY-MM-DD_hhmm/model.ckpt-NNNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    device_count = {'GPU': 0}\n",
    ")\n",
    "\n",
    "testDataNum = sum([1 for record  in tf.python_io.tf_record_iterator(\"test_tf_file_128x128.tfrecords\")])\n",
    "batchSize = 50\n",
    "\n",
    "files = []\n",
    "accuracyResults = []\n",
    "actualResults= []\n",
    "expectResults = []\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "        \n",
    "    # 入力層\n",
    "    filenames = tf.placeholder(tf.string, shape=[None])\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function, batchSize)  # レコードを解析し、テンソルに変換\n",
    "    dataset = dataset.map(read_image, batchSize)  # データの形式、形状を変更\n",
    "    dataset = dataset.batch(batchSize)  # 連続するレコードをバッチに結合\n",
    "    iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)  # イテレータを作成\n",
    "    images, labels, paths = iterator.get_next()  # イテレータの次の要素を取得\n",
    "    \n",
    "    initOp = iterator.make_initializer(dataset)  # イテレータを初期化\n",
    "        \n",
    "    model = Model(images, DST_INPUT_SIZE, NUM_CLASS, batchSize, trainable=False, labels=labels)\n",
    "        \n",
    "    with tf.Session(config=config) as session:\n",
    "        session.run(initOp, feed_dict={filenames: [\"test_tf_file_128x128.tfrecords\"]})  # データの初期化\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        saver.restore(session, ckptPath)\n",
    "\n",
    "        for i in range(math.ceil(testDataNum / batchSize)):\n",
    "            file, accuracyResult, actualResult, expectResult = session.run([paths, model.accuracy, model.logits, labels], feed_dict={model.keepProb: 1.0, model.isTraining: False})\n",
    "            files.extend(file)\n",
    "            accuracyResults.append(accuracyResult)\n",
    "            actualResults.extend(actualResult)\n",
    "            expectResults.extend(expectResult)\n",
    "            \n",
    "goods = []\n",
    "bads = []\n",
    "for index, (actual, expect) in enumerate(zip(actualResults, expectResults)):\n",
    "    if np.argmax(actual) == np.argmax(expect):\n",
    "        goods.append(files[index])\n",
    "    else:\n",
    "        bads.append(files[index])\n",
    "    \n",
    "    compareResult = []\n",
    "    for expect, actual in zip(expectResults, actualResults):\n",
    "        compareResult.append((np.argmax(expect), np.argmax(actual)))\n",
    "        \n",
    "print('accuracy: ', sum(accuracyResults) / len(accuracyResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyResultAndName = []\n",
    "\n",
    "for index in range(len(names)):\n",
    "    memberName = [key for key, value in names.items() if value == index][0]\n",
    "    allTestFile = [filename.decode('utf-8') for filename in files if memberName in filename.decode('utf-8')]\n",
    "    gooddResults = [filename.decode('utf-8') for filename in goods if memberName in filename.decode('utf-8')]\n",
    "    accuracyResultAndName.append({'name': memberName, 'accuracy': len(gooddResults) / len(allTestFile)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyResultAndName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfrecordFile = \"train_tf_file_128x128.tfrecords\"\n",
    "trainDataNum = sum([1 for record  in tf.python_io.tf_record_iterator(tfrecordFile)])\n",
    "batchSize = 50\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    device_count = {'GPU': 0}\n",
    ")\n",
    "\n",
    "files = []\n",
    "accuracyResults = []\n",
    "actualResults= []\n",
    "expectResults = []\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "        \n",
    "    # 入力層\n",
    "    filenames = tf.placeholder(tf.string, shape=[None])\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function, batchSize)  # レコードを解析し、テンソルに変換\n",
    "    dataset = dataset.map(read_image, batchSize)  # データの形式、形状を変更\n",
    "    dataset = dataset.batch(batchSize)  # 連続するレコードをバッチに結合\n",
    "    iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)  # イテレータを作成\n",
    "    images, labels, paths = iterator.get_next()  # イテレータの次の要素を取得\n",
    "    \n",
    "    initOp = iterator.make_initializer(dataset)  # イテレータを初期化\n",
    "        \n",
    "    model = Model(images, labels, DST_INPUT_SIZE, NUM_CLASS, batchSize, trainable=False)\n",
    "        \n",
    "    with tf.Session(config=config) as session:\n",
    "        session.run(initOp, feed_dict={filenames: [tfrecordFile]})  # データの初期化\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        saver.restore(session, ckptPath)\n",
    "        \n",
    "        for i in range(int(testDataNum / batchSize)):\n",
    "            file, accuracyResult, actualResult, expectResult = session.run([paths, model.accuracy, model.logits, labels], feed_dict={model.keepProb: 1.0, model.isTraining: False})\n",
    "            files.extend(file)\n",
    "            accuracyResults.append(accuracyResult)\n",
    "            actualResults.extend(actualResult)\n",
    "            expectResults.extend(expectResult)\n",
    "\n",
    "\n",
    "goods = []\n",
    "bads = []\n",
    "for index, (actual, expect) in enumerate(zip(actualResults, expectResults)):\n",
    "    if np.argmax(actual) == np.argmax(expect):\n",
    "        goods.append(files[index])\n",
    "    else:\n",
    "        bads.append(files[index])\n",
    "    \n",
    "    compareResult = []\n",
    "    for expect, actual in zip(expectResults, actualResults):\n",
    "        compareResult.append((np.argmax(expect), np.argmax(actual)))\n",
    "        \n",
    "print('accuracy: ', sum(accuracyResults) / len(accuracyResults))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
